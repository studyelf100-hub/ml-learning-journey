# ğŸ§  Machine Learning Notes  
*A growing collection of explanations, summaries, and insights from my ML studies.*

---

## ğŸ“Œ Table of Contents
1. [Foundations](#foundations)  
2. [Math for ML](#math-for-ml)  
3. [Python + Tools](#python--tools)  
4. [Core ML Concepts](#core-ml-concepts)  
5. [Algorithms & Models](#algorithms--models)  
6. [Deep Learning](#deep-learning)  
7. [NLP + Transformers](#nlp--transformers)  
8. [Experiments & Reflections](#experiments--reflections)

---

## ğŸ£ Foundations

### **What is Machine Learning?**  
Machine Learning is the field where computers learn patterns from data without being manually programmed for every rule.  
There are three main types:

- **Supervised Learning** â†’ Predict a label  
- **Unsupervised Learning** â†’ Discover structure  
- **Reinforcement Learning** â†’ Learn by trial & error

### **Why ML Matters**  
Because it automates decision-making in:
- Healthcare  
- Finance  
- Search engines  
- Recommender systems  
- Robotics  
- AI research (my future specialty)

---

## ğŸ“ Math for ML

### **Linear Algebra**
The language of neural networks.
- Vectors  
- Matrices  
- Matrix multiplication  
- Dot products  
- Linear transformations  

**Why it matters:**  
Neural networks **are** just giant stacks of matrix operations.

---

### **Calculus**
Especially:
- Derivatives  
- Partial derivatives  
- Gradients  
- Chain rule  

**Why it matters:**  
Backpropagation = using calculus to adjust model weights.

---

### **Statistics**
- Mean, variance, standard deviation  
- Distributions  
- Probability  
- Bayesâ€™ theorem  

**Why it matters:**  
Every ML model tries to understand probability patterns.

---

## ğŸ Python + Tools

### **Python Core**
- Loops  
- Functions  
- Classes  
- List/dict manipulation  
- Error handling  

### **ML Libraries**
- **NumPy** â†’ math  
- **Pandas** â†’ data  
- **Matplotlib** â†’ visuals  
- **Scikit-learn** â†’ foundational ML  

### **Tools**
- Git + GitHub  
- VS Code  
- Jupyter notebooks  
- Virtual environments  

---

## ğŸŒ± Core ML Concepts

### **Dataset**
Your modelâ€™s food.

### **Features**
The inputs (X).

### **Labels**
The outputs (y).

### **Training vs. Testing**
- **Training set** â†’ model learns  
- **Testing set** â†’ model proves it learned  

### **Overfitting**
Model memorizes instead of understanding.  
*worse than cheating on a test.*

### **Underfitting**
Model didnâ€™t learn enough.

---

## ğŸ“Š Algorithms & Models

### **Supervised**  
- Linear Regression  
- Logistic Regression  
- Decision Trees  
- Random Forests  
- SVM  
- KNN  

### **Unsupervised**  
- K-means  
- PCA  
- Hierarchical clustering  

---

## ğŸ§  Deep Learning

### **Neural Network Basics**
- Neurons  
- Layers  
- Activation functions (ReLU, sigmoid, tanh)  
- Loss functions  
- Optimizers (SGD, Adam)  
- Backpropagation  

### **Why Deep Learning Works**
It automatically extracts features instead of requiring manual engineering.

---

## ğŸ”¤ NLP + Transformers

### **NLP Tasks**
- Tokenization  
- Embeddings  
- Text classification  
- Sequence-to-sequence learning  

### **Transformers**
Modern AI is built on them.

Key ideas:
- Attention  
- Multi-head attention  
- Positional encoding  
- Encoderâ€“decoder architecture  

Libraries:
- **Hugging Face Transformers**  
- **Tokenizers library**  

---

## ğŸ” Experiments & Reflections

### **Experiment 1: My first dataset**
- What I tried  
- What failed  
- What worked  
- What I learned  

> â€œMistakes documented here become wisdom later.â€

(Add entries as you go.)

---

# ğŸˆâ€â¬› End of Notes  
*This file will grow as my knowledge grows.*
